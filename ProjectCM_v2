
NAME = "CAMELIA MARIN"
COLLABORATORS = ""
Group Project - CO2 emissions
Problem Statement:

Our group would like to explore how income levels and countries that are considered developed versus developing have contributed to the CO2 emissions. We would like to use the analysis to explain how the income and GDP per capital correlate to CO2 emissions levels.

Datasets:

https://www.kaggle.com/code/catamount11/who-is-responsible-for-global-warming/input?select=API_EN.ATM.CO2E.PC_DS2_en_csv_v2_10576797.csv

https://www.kaggle.com/code/catamount11/who-is-responsible-for-global-warming/input?select=Metadata_Country_API_EN.ATM.CO2E.PC_DS2_en_csv_v2_10576797.csv

https://www.kaggle.com/datasets/cv13j0/gpd-gpd-per-capita-by-country

Hypotheses:

There is a significant difference in per capita CO2 emissions between developed and developing countries.
CO2 emissions have increased over time in most countries.
CO2 emissions are positively correlated with GDP per capita.
To validate our hypotheses, we will take the following approach:

Create a data set by combining the three datasets. 
Clean the dataset by imputing missing values, standardizing columns, creating dummy
variables.
We will analyse the distribution of CO2 Emissions by Income Groups. We have four different groups of countries: low income, lower middle income, upper middle income and high income countries.
Summarize results in a report organized by each hypothesis.
# all imports and env variables
import numpy as np  
import pandas as pd  
import matplotlib.pyplot as plt
 
 
Dataset Overview

This data set is about the global warming co2 emissions by various countries in the time period between 1960 to 2014. The data has information about low income and high income countries and countries are categorized by regions.

#Read the data
df = pd.read_csv('API_EN.ATM.CO2E.PC_DS2_en_csv_v2_10576797.csv') 
meta_data= pd.read_csv('Metadata_Country_API_EN.ATM.CO2E.PC_DS2_en_csv_v2_10576797.csv')
gdp = pd.read_csv('API_NY.GDP.PCAP.CD_DS2_en_csv_v2_53584172.csv')
​
# Note. Renamed to csv, gpd csv renamed to remove a gap in the original file name
# Note. The files downloaded as xls file.
​
#Joining the DataFrames using Country Code as join key
#1. check the quality of the data
# print(df.columns)  
""" 2015          0 non-null      float64
    2016          0 non-null      float64
    2017          0 non-null      float64
    2018          0 non-null      float64 
Unnamed: 63     0 non-null      float64 """
#Drop columns with null values
df.drop(['2015','2016','2017','2018','Unnamed: 63'], axis = 1,inplace=True)
#Drop columns not required 
df.drop(['Indicator Name','Indicator Code'], axis = 1,inplace=True) 
#print(df.info())
​
#Drop columns with null values
gdp.drop(['2015','2016','2017','2018','2019','2020','2021'], axis = 1,inplace=True) 
#Drop columns not required 
gdp.drop(['Indicator Name','Indicator Code'], axis = 1,inplace=True) 
#print(gdp.info())
​
#print(meta_data.columns)
"""  Unnamed: 5    0 non-null      float64 """
meta_data.drop(['Unnamed: 5'], axis = 1,inplace=True)
#Drop columns not required 
meta_data.drop(['SpecialNotes','TableName'], axis = 1,inplace=True) 
#print(meta_data.info())
​
#2a. check the quality of the join key. Check if some country code from the df data are not in the meta_data
missing_codes_df = df[~df['Country Code'].isin(meta_data['Country Code'])]
#print(missing_codes_df)
"""return 108   Not classified  INX .... The record can be dropped"""
df.drop(df.index[108],inplace= True)
​
#2b. check the quality of the join key. Check if some country code from the gdp data are not in the meta_data
missing_codes_gdp = gdp[~gdp['Country Code'].isin(meta_data['Country Code'])]
#print(missing_codes_gdp)
"""return 1, 3, 110 Not classified  INX .... The record can be dropped"""
gdp.drop(index=[1,3,110],inplace= True)
​
​
#3a. Join the DataFrames 
joined_df = pd.merge(left = meta_data , right = df , how = 'inner', on = 'Country Code' )
#3b. Join the DataFrames 
joined_df = pd.merge(left=joined_df, right=gdp, how='inner', on='Country Code')
​
​
# print(df.shape)
# print(meta_data.shape)
# print(joineddf.shape)
​
# print(df.head)
# print(meta_data.head)
# print(joineddf.head)
# print(joineddf.info())
​
​
​
#4. Reshape the Dataframe. Unpivot the DataFrame from wide to long format, var_name= 'year', value_name= 'CO2Emissions' 
#melted_df= pd.melt(joined_df, id_vars=['Country Code','Region', 'IncomeGroup','Country Name'], var_name= 'Year', value_name= 'CO2Emissions')
melted_df = pd.melt(joined_df, id_vars=['Country Code', 'Region', 'IncomeGroup', 'Country Name_x'], var_name='Year', value_name='CO2Emissions')
​
# print(melted_df.shape)
# print(melted_df.info())
#Year column are object, change the data type to date to int
melted_df['Year'] = pd.to_numeric(melted_df['Year'].str.replace('_x', '').str.replace('_y', ''), errors='coerce')
melted_df = melted_df.dropna(subset=['Year']).astype({'Year': 'int'})
​
#melted_df['Year']= melted_df['Year'].astype('int')
# print(melted_df.info())
​
#5. Check for duplicates, if any drop them
melted_df.drop_duplicates(inplace=True) 
​
#6. Check if the values for the co2 emission are correct (i.e. negative values are not correct) and drop them 
melted_df.drop(melted_df[melted_df['CO2Emissions'] <0].index, inplace=True )
#print(melted_df.loc[melted_df['CO2Emissions'] <0]) 
​
#7. Check for missing values %
# print(melted_df.isnull().sum()/ melted_df.shape[0] * 100.00)
# print(melted_df.shape)
​
# For the rows where the Region is na, the Country Name is not a coutry per se. The rows can be droped. 
# After dropping the rows we have about 17% rows missing data for CO2Emissions 
# In melted_df rows missing data for CO2Emissions include rows missing data for Region. We'll get the same resultdata if we drop all the na vaues from melted_df
​
""" melted_df2=melted_df[melted_df['Region'].notna()] 
melted_df3=melted_df2.dropna()
print(melted_df2.isnull().sum()/ melted_df2.shape[0] * 100.00) 
print(melted_df2.shape)
print(melted_df3.isnull().sum()/ melted_df3.shape[0] * 100.00)
print(melted_df3.shape)
​
melted_df4=melted_df.dropna()
print(melted_df4.isnull().sum()/ melted_df4.shape[0] * 100.00)
print(melted_df4.shape) """
​
# Drop all the na vaues from melted_df
melted_df.dropna(inplace=True)
# print(melted_df.isnull().sum()/ melted_df.shape[0] * 100.00)
# print(melted_df.shape)  
 
​
Index(['Country Code', 'Region', 'IncomeGroup', 'Country Name_x', 'Year',
       'CO2Emissions'],
      dtype='object')
When plotting CO2 emissions over time, the mean value can give us an idea of the central tendency of the data and how it changes over the years. It also allows us to compare the average emissions across different years and/or regions.

Using the mean can be useful when we want to identify trends or patterns in the data. For example, if the mean CO2 emissions are increasing over the years, we can infer that there is a general trend of rising emissions. Similarly, if the mean emissions are decreasing, we can infer that emissions are decreasing over time.

# Data visualization
 
mean_df = melted_df.groupby('Region')['CO2Emissions'].mean()

# Converting the Series to a DataFrame
mean_df = mean_df.reset_index()

# Renaming the columns
mean_df.columns = ['Region', 'CO2Emissions']


colors_region=['Red','Blue','Green','Yellow','Purple','Orange','Brown']
pie1=mean_df.plot(figsize=(8,8) ,kind='pie', y='CO2Emissions', autopct='%1.0f%%',
                                colors = colors_region,  legend = None, ylabel="", shadow=True   
                            )

pie1.set_title('Distribution of CO2 Emissions by Region',fontdict={'fontsize':20})
#The highest share of CO2 emmisions are produced in North America - 36%, followed by Middle East & North Africa with 24%. Both two regions produce 60% of the world CO2 emissions.
 

mean_df = melted_df.groupby('IncomeGroup')['CO2Emissions'].mean()

# Converting the Series to a DataFrame
mean_df = mean_df.reset_index()

# Renaming the columns
mean_df.columns = ['Region', 'CO2Emissions']

pie2=mean_df.plot(figsize=(8,8) ,kind='pie', y='CO2Emissions', autopct='%1.0f%%',
                                colors = colors_region,  legend = None, ylabel="", shadow=True  
                                )
pie2.set_title('Distribution of CO2 Emissions by Income Groups', fontdict={'fontsize':20})
#The High income countries share of CO2 are 71% of worlds CO2 emissions. Low income and Lower middle income group countries are responssible for only 8% of worlds CO2 emissions.


fig, ax = plt.subplots(figsize = (20,10)) 
melted_df.groupby('Year')['CO2Emissions'].mean().plot(ax = ax, color = 'black', label = 'Worldwide')
melted_df[melted_df['IncomeGroup'] == 'High income'].groupby('Year')['CO2Emissions'].mean().plot(ax = ax, color = 'red', label = 'High income countries')
melted_df[melted_df['IncomeGroup'] == 'Upper middle income'].groupby('Year')['CO2Emissions'].mean().plot(ax = ax, color = 'orange', label = 'Upper middle income countries')
melted_df[melted_df['IncomeGroup'] == 'Lower middle income'].groupby('Year')['CO2Emissions'].mean().plot(ax = ax, color = 'blue', label = 'Lower middle income countries')
melted_df[melted_df['IncomeGroup'] == 'Low income'].groupby('Year')['CO2Emissions'].mean().plot(ax = ax, color = 'green', label = 'Low income countries')
plt.xlabel('Year', fontsize = 16)
plt.ylabel('Average CO2 Emissions (Metric Tons per Capita)', fontsize = 18)
plt.title('Dynamics of Average CO2 Emissions Over The Years', fontsize = 20)
plt.legend(fontsize = 16)
plt.show()
#High income countries generates CO2 emission above the world average for whole period 1960 - 2014.


​
